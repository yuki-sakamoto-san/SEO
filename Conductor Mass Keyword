import time
import hashlib
import requests
import pandas as pd

def gen_api_sig(api_key, shared_secret):
    m = hashlib.md5()
    m.update(api_key.encode())
    m.update(shared_secret.encode())
    epoch_sec = int(time.time())
    m.update(str(epoch_sec).encode())
    hex_digest = m.hexdigest()
    return hex_digest

def build_signed_url(base_url, api_key, shared_secret):
    signature = gen_api_sig(api_key, shared_secret)
    signed_url = f"{base_url}?apiKey={api_key}&sig={signature}"
    return signed_url

def get_conductor_data(signed_url, region=None):
    headers = {
        'Content-Type': 'application/json',
        'Accept': 'application/json'
    }
    cookies = {}
    if region:
        cookies['cndr_region'] = region

    try:
        response = requests.get(signed_url, headers=headers, cookies=cookies)
        response.raise_for_status()  # Raise an error for bad status codes
        data = response.json()
        return data
    except requests.RequestException as e:
        print(f"Error fetching data: {e}")
        if response is not None:
            print(response.text)  # Print response text for debugging
        return None

def parse_conductor_data(data):
    # Parse the Conductor data to extract relevant information
    if 'records' in data:
        records = data['records']
        parsed_data = []
        for record in records:
            parsed_data.append({
                'Keyword': record.get('keyword', 'N/A'),
                'Search Volume': record.get('search_volume', 'N/A'),
                'SERP Features': record.get('serp_features', 'N/A'),
                'Keyword Difficulty': record.get('keyword_difficulty', 'N/A')
            })
        return parsed_data
    else:
        return []

def create_dataframe(parsed_data):
    df = pd.DataFrame(parsed_data)
    return df

def export_to_excel(dataframes, output_file):
    with pd.ExcelWriter(output_file, engine='openpyxl') as writer:
        if not dataframes:
            print("No data to write to Excel.")
            return
        for country, df in dataframes.items():
            if not df.empty:
                df.to_excel(writer, sheet_name=country, index=False)
            else:
                print(f"No data for country: {country}")

def main():
    # User inputs
    api_key = input("Enter your Conductor API key: ")
    shared_secret = input("Enter your Conductor API shared secret: ")
    keywords = input("Enter the SEO keywords (comma separated): ").split(',')
    countries = input("Enter the countries (comma separated, e.g., 'us,uk,de'): ").split(',')
    region = input("Enter the region (optional, e.g., 'eu-west-1' for EU): ")

    base_url = "https://app.conductor.com/v3/keywords/search-volumes"
    
    all_dataframes = {}

    for country in countries:
        country = country.strip()
        all_data = []
        
        for keyword in keywords:
            keyword = keyword.strip()
            print(f"Fetching data for keyword '{keyword}' in country '{country}'")
            signed_url = build_signed_url(base_url, api_key, shared_secret)
            data = get_conductor_data(signed_url, region)
            if data:
                parsed_data = parse_conductor_data(data)
                df = create_dataframe(parsed_data)
                all_data.append(df)
        
        # Concatenate all dataframes for the current country
        if all_data:
            country_df = pd.concat(all_data, ignore_index=True)
            all_dataframes[country] = country_df

    # Export all dataframes to an Excel file
    output_file = "conductor_seo_analysis.xlsx"
    export_to_excel(all_dataframes, output_file)
    print(f"Data exported to {output_file}")

if __name__ == "__main__":
    main()
